class category_node:
    def __init__(self,name):
        self.c_name=name
        self.count=1
        self.parent=[]
        self.references={}
        self.news_sources={}
def check_for_special_char(s):
    for i in s:
        if i.isdigit() or i in " ?.!/;:":
            return True
            break
    return False
def check_for_category(cat):
    if len(cat)>4 and len(cat)<20 and check_for_special_char(cat)is not True:
        return True
    else:
        return False
def url_category_list(s):
    cat_list=[]
    if s[0]=='/':
        sp=s.split('/')[1:]
    else:
        sp=s.split('/')[1:]
    for i in range(0,len(sp)):
        y=sp[i].strip('-_,. :').lower()
        if check_for_category(y):
             cat_list.append(y)
    return cat_list
def source_fetcher():
    db = MySQLdb.connect("localhost",user="root",db="temporary_category_classification")
    cursor = db.cursor()
    
    sql="select * from level_1 
    url_list=[]
    try:
        cursor.execute(sql)            
        result=cursor.fetchall()
        url_list=list(result)
    except:
        print "error in selection"
    db.close()
    for e in url_list:
        print e
def url_reader(threadName,url):
    path="D://Thesis//data//indian_news_url//"
    filename=os.listdir(path)
    valid_url=[0,0]
    for i in range(0,len(filename)):
        file1=path+filename[i]
        #print file1
        f=open(file1,"rb")
        reader1 = csv.reader(f,delimiter=',')
        row=list(reader1)
        print 'length of url is',len(row)
        f.close()
        for row1 in row:
            if len(row1)==1:
                domain_name=row1[0]
                #print domain_name
                if url.has_key(domain_name):
                        url[domain_name]=url[domain_name]+1
                else:
                    url[domain_name]=1
                    #print domain_name
                    category_domain_info(domain_name,valid_url)
                    #loc(domain_name)
        #print "\ndate",ac_date
        #print "toal urls\n",len(url)
        #print "\ttotal unique urls are",len(url)
        print "\t file procees are\t",i
    print len(url)
    print valid_url
def category_domain_info(element,valid_url):
        """splitted_url=element.split("/")
        length=len(splitted_url)
        if length>2:
            valid_url[0]=valid_url[0]+1
            dom=splitted_url[2]
            cat_list=[]
            for i in range(3,len(splitted_url)):
                st=splitted_url[i].strip("")
                try:
                    #if d.check(y):
                        y=st.lower()                        
                        if check_for_category(y):
                            cat_list.append(y)
                except:
                    pass"""
            #if 'bhopal' in cat_list:
            #print cat_list
            #if len(cat_list)==0 and len(splitted_url)!=3:
                #valid_url[1]=valid_url[1]+1
            #    print element
        cat_list=url_category_list(element)
        i=0
        while i<len(cat_list)-1:
            if category.has_key(cat_list[i]):
                ref=category[cat_list[i]]
                ref.count=ref.count+1
                if ref.news_sources.has_key(element):
                    ref.news_sources[element]=ref.news_sources[element]+1
                
                else:
                    ref.news_sources[element]=1
                temp=ref.references                    
                if temp.has_key(cat_list[i+1]):
                    temp[cat_list[i+1]]=temp[cat_list[i+1]]+1
                    category[cat_list[i]]=ref
                else:                        
                    temp[cat_list[i+1]]=1
                category[cat_list[i]]=ref
                if category.has_key(cat_list[i+1]):
                    x=category[cat_list[i+1]]
                    if category[cat_list[i]].c_name not in x.parent:
                        x.parent.append(category[cat_list[i]].c_name)
                    category[cat_list[i+1]]=x
                else:
                    new_c=category_node(cat_list[i+1])
                    if category[cat_list[i]].c_name not in new_c.parent:
                        new_c.parent.append(category[cat_list[i]].c_name)
                    category[cat_list[i+1]]=new_c
            else:
                new_cat=category_node(cat_list[i])
                new_cat.count=1
                new_cat.news_sources[element]=1
                new_cat.references[cat_list[i+1]]=1
                category[cat_list[i]]=new_cat
                if category.has_key(cat_list[i+1]):
                    x=category[cat_list[i+1]]
                    if category[cat_list[i]].c_name not in x.parent:
                        x.parent.append(category[cat_list[i]].c_name)
                    category[cat_list[i+1]]=x
                else:
                    new_c=category_node(cat_list[i+1])
                    if category[cat_list[i]].c_name not in new_c.parent:
                        new_c.parent.append(category[cat_list[i]].c_name)
                    category[cat_list[i+1]]=new_c
            i=i+1
            if i>0:
                if category.has_key(cat_list[i]):
                    obj=category[cat_list[i]]
                    obj.count=obj.count+1
                    if obj.news_sources.has_key(element):
                            obj.news_sources[element]=obj.news_sources[element]+1
                    else:
                            obj.news_sources[element]=1
                    category[cat_list[i]]=obj
                else:
                      new_cat=category_node(cat_list[0])
                      new_cat.count=1
                      new_cat.news_sources[element]=1
                      category[cat_list[0]]=new_cat



url={}
category={}
domain={}

source_fetcher()
